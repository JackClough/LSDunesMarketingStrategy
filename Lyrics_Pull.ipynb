{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bac971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords as sw\n",
    "sw = stopwords.words('English')\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pprint as pprint\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "punctuation = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b8e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azlyrics.azlyrics import artists, songs, lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0769288",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"related_artist_songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2825f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_artists = d['Artist'].to_list()\n",
    "new_list_songs = d['Song'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203e5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data = defaultdict(lambda: defaultdict(lambda: defaultdict(str)))\n",
    "\n",
    "\n",
    "for artist, song in zip(new_list_artists, new_list_songs) :\n",
    "    #wd = lyrics(artist, song)\n",
    "    data[artist][song] = ''\n",
    "    #for song in songs : \n",
    "        #data[artist][song] = \"this would be lyrics\"\n",
    "        #data[artist][song]['tokens'] = \"this would be lyrics\".split()\n",
    "        #data[artist][song]['speechiness'] = random.random()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd402d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link = 'https://www.azlyrics.com/lyrics/'\n",
    "\n",
    "def generate_link(artist, song) :\n",
    "    \n",
    "    for artist in data.keys():\n",
    "        artist_lc = artist.lower()\n",
    "        artist_sw = artist_lc.removeprefix('the ')\n",
    "        artist_space = artist_sw.replace(' ', '')\n",
    "        artist_punc = \"\".join([ch for ch in artist_space if ch not in punctuation])\n",
    "        for song in data[artist]:\n",
    "            song_lc = song.lower()\n",
    "            sep = \"feat.\"\n",
    "            sep2 = \"(\"\n",
    "            song_stripped = song_lc.split(sep, 1)[0]\n",
    "            song_stripped = song_stripped.split(sep2, 1)[0]\n",
    "            song_punc = \"\".join([ch for ch in song_stripped if ch not in punctuation])\n",
    "            song_space = song_punc.replace(' ', '')\n",
    "            link = (base_link + artist_punc + '/' + song_space + '.html')\n",
    "            #list_of_links.append(link)\n",
    "            data[artist][song] = link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57af4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in data.keys() :\n",
    "    for song in data[artist] :\n",
    "        generate_link(artist, song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8280fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_song(song) :\n",
    "    song_lc = song.lower()\n",
    "    sep = \"feat.\"\n",
    "    sep2 = \"(\"\n",
    "    song_stripped = song_lc.split(sep, 1)[0]\n",
    "    song_stripped = song_lc.split(sep2, 1)[0]\n",
    "    song_punc = \"\".join([ch for ch in song_stripped if ch not in punctuation])\n",
    "    song_space = song_punc.replace(' ', '')\n",
    "    \n",
    "    \n",
    "    # tack on .txt\n",
    "    name = song_space + \".txt\"\n",
    "\n",
    "    return(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2785d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"lyrics\") : \n",
    "    shutil.rmtree(\"lyrics/\")\n",
    "\n",
    "os.mkdir(\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e36bde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n",
      "already exists!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "total_pages = 0 \n",
    "\n",
    "for artist in data.keys():\n",
    "\n",
    "    artist_lc = artist.lower()\n",
    "    artist_sw = artist_lc.removeprefix('the ')\n",
    "    artist_space = artist_sw.replace(' ', '')\n",
    "    artist_punc = \"\".join([ch for ch in artist_space if ch not in punctuation])\n",
    "    \n",
    "    if not os.path.exists(\"lyrics/\" + artist_punc):\n",
    "        os.mkdir(\"lyrics/\" + artist_punc)\n",
    "        pages = 0\n",
    "    \n",
    "        for song, link in data[artist].items() :\n",
    "        \n",
    "            song_name = song\n",
    "            print(f\"Requesting: {song_name}\")\n",
    "        \n",
    "            url =  link\n",
    "            print(f\"{url}\")\n",
    "        \n",
    "        # request\n",
    "            r = requests.get(url)\n",
    "            time.sleep(5 + 10*random.random()) # Put in a random wait\n",
    "\n",
    "            pages += 1\n",
    "        \n",
    "            if r.status_code != 200 :\n",
    "                print(f\"Got a bad status code ({r.status_code}) on {song}.\")\n",
    "            else :\n",
    "                soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            \n",
    "            #generate_filename_from_link(url)\n",
    "            #output_filename = \"lyrics/\" + artist_punc + \"/\" + generate_filename_from_link(song)\n",
    "                output_filename = \"lyrics/\" + artist_punc + \"/\" + generate_filename_from_song(song)\n",
    "            \n",
    "            \n",
    "            # Let's get the lyrics\n",
    "                hit_ringtone = False\n",
    "                for item in soup.find_all(\"div\") : \n",
    "                \n",
    "                # Lyrics are the div after the ringtone\n",
    "                    if hit_ringtone : \n",
    "                        break\n",
    "\n",
    "                    if \"class\" in item.attrs : \n",
    "                        if \"ringtone\" in item.attrs[\"class\"] : \n",
    "                            hit_ringtone = True\n",
    "\n",
    "                lyrics = item.text\n",
    "    \n",
    "        \n",
    "                with open(output_filename,'w', encoding = \"utf-8\") as ofile :\n",
    "                    ofile.write(lyrics)\n",
    "        time.sleep(10)\n",
    "        total_pages += pages\n",
    "    else:\n",
    "            print('already exists!')\n",
    "            pass\n",
    "    # Sleep between artists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "total_pages = 0 \n",
    "\n",
    "for artist in data.keys():\n",
    "\n",
    "    #artist_lc = artist.lower()\n",
    "    #artist_sw = artist_lc.removeprefix('the ')\n",
    "    #artist_space = artist_sw.replace(' ', '')\n",
    "    #artist_punc = \"\".join([ch for ch in artist_space if ch not in punctuation])\n",
    "    \n",
    "    if not os.path.exists(\"lyrics/\" + artist_punc):\n",
    "        os.mkdir(\"lyrics/\" + artist_punc)\n",
    "        pages = 0\n",
    "    \n",
    "        for song, link in data[artist].items() :\n",
    "        \n",
    "            song_name = song\n",
    "            print(f\"Requesting: {song_name}\")\n",
    "        \n",
    "            url =  link\n",
    "            print(f\"{url}\")\n",
    "        \n",
    "        # request\n",
    "            r = requests.get(url)\n",
    "            time.sleep(5 + 10*random.random()) # Put in a random wait\n",
    "\n",
    "            pages += 1\n",
    "        \n",
    "            if r.status_code != 200 :\n",
    "                print(f\"Got a bad status code ({r.status_code}) on {song}.\")\n",
    "            else :\n",
    "                soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            \n",
    "            #generate_filename_from_link(url)\n",
    "            #output_filename = \"lyrics/\" + artist_punc + \"/\" + generate_filename_from_link(song)\n",
    "                output_filename = \"lyrics/\" + artist_punc + \"/\" + generate_filename_from_song(song)\n",
    "            \n",
    "            \n",
    "            # Let's get the lyrics\n",
    "                hit_ringtone = False\n",
    "                for item in soup.find_all(\"div\") : \n",
    "                \n",
    "                # Lyrics are the div after the ringtone\n",
    "                    if hit_ringtone : \n",
    "                        break\n",
    "\n",
    "                    if \"class\" in item.attrs : \n",
    "                        if \"ringtone\" in item.attrs[\"class\"] : \n",
    "                            hit_ringtone = True\n",
    "\n",
    "                lyrics = item.text\n",
    "    \n",
    "        \n",
    "                with open(output_filename,'w', encoding = \"utf-8\") as ofile :\n",
    "                    ofile.write(lyrics)\n",
    "        time.sleep(10)\n",
    "        total_pages += pages\n",
    "    else:\n",
    "            print('already exists!')\n",
    "            pass\n",
    "    # Sleep between artists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023cc30",
   "metadata": {},
   "source": [
    "Example of statistics for the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4292ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\jackc\\\\OneDrive\\\\Documents\\\\MSBA\\\\Capstone Project\\\\lyrics\\\\mychemicalromance\\\\\"\n",
    "\n",
    "teenagers = open(path + 'teenagers.txt', 'r', encoding = 'utf-8').read()\n",
    "\n",
    "txt_clean = [w for w in teenagers.split()]\n",
    "txt_clean = [w.lower() for w in txt_clean if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c40e1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path)\n",
    "\n",
    "for file in file_list:\n",
    "    lyrics = open(path + file, 'r').read()\n",
    "    txt_clean = [w for w in lyrics.split()]\n",
    "    txt_clean = [w.lower() for w in txt_clean if w.isalpha() and w not in sw]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6bd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patterns(text)  :\n",
    "    \"\"\"\n",
    "        This function takes text as an input and returns a dictionary of statistics,\n",
    "        after cleaning the text. \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    total_tokens = 1\n",
    "    unique_tokens = 0\n",
    "    avg_token_len = 0.0\n",
    "    lex_diversity = 0.0\n",
    "    top_10 = Counter()\n",
    "    \n",
    "    # Do your tokenization and normalization here\n",
    "    txt_clean = [word.lower() for word in text.split()]\n",
    "    txt_clean = [word for word in txt_clean if word.isalpha() and word not in sw]\n",
    "    \n",
    "    \n",
    "    # Calculate your statistics here\n",
    "    total_tokens = len(txt_clean)\n",
    "    \n",
    "    unique_tokens = len(set(txt_clean))\n",
    "    \n",
    "    txt_token_length = [len(word) for word in txt_clean]\n",
    "    avg_token_len = np.mean(txt_token_length)\n",
    "    \n",
    "    lex_diversity = len(set(txt_clean))/len(txt_clean)\n",
    "    \n",
    "\n",
    "    txt_fd = FreqDist(txt_clean)\n",
    "    top_10 = txt_fd.most_common(10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Now we'll fill out the dictionary. \n",
    "    results = {'tokens':total_tokens,\n",
    "               'unique_tokens':unique_tokens,\n",
    "               'avg_token_length':avg_token_len,\n",
    "               'lexical_diversity':lex_diversity,\n",
    "               'top_10':top_10}\n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd7b30ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#txt_clean = [w for w in lyrics.split()]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#txt_clean = [w.lower() for w in txt_clean if w.isalpha() and w not in sw]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#song_len = [len(w) for w in txt_clean]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(f\"{song}'s average token length is {np.mean(song_len):.2f}.\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m get_patterns(lyrics)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMy Chemical Romance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for song in data['My Chemical Romance']:\n",
    "    \n",
    "    if song == \"I'm Not Okay (I Promise)\":\n",
    "        continue\n",
    "        \n",
    "    if song == \"Under Pressure\":\n",
    "        continue\n",
    "    \n",
    "    clean_song = clean_song_name(song)\n",
    "    lyrics = open(path + clean_song + '.txt', 'r').read()\n",
    "    #txt_clean = [w for w in lyrics.split()]\n",
    "    #txt_clean = [w.lower() for w in txt_clean if w.isalpha() and w not in sw]\n",
    "    \n",
    "    #song_len = [len(w) for w in txt_clean]\n",
    "\n",
    "    #print(f\"{song}'s average token length is {np.mean(song_len):.2f}.\")\n",
    "    \n",
    "    results = get_patterns(lyrics)\n",
    "    \n",
    "    data['My Chemical Romance'].update[results]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114039e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vector of token length\n",
    "_len = [len(w) for w in beo_clean]\n",
    "\n",
    "print(f\"Beowulf's average token length is {np.mean(beo_token_len):.2f}.\")\n",
    "\n",
    "pprint(sorted(Counter(beo_token_len).items()))\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated after normalization and tokenization.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03b43495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_song_name(song):\n",
    "    song_lc = song.lower()\n",
    "    sep = \"feat.\"\n",
    "    sep2 = \"(\"\n",
    "    song_stripped = song_lc.split(sep, 1)[0]\n",
    "    song_stripped = song_stripped.split(sep2, 1)[0]\n",
    "    song_space = song_stripped.replace(' ', '')\n",
    "    song_punc = \"\".join([ch for ch in song_space if ch not in punctuation])\n",
    "    clean_song = song_punc\n",
    "    \n",
    "    return(clean_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abeb76b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teenagers is 255 tokens long.\n",
      "Teenagers has 88 unique tokens.\n",
      "Teenagers' lexical diversity is 0.345.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teenagers is {len(txt_clean)} tokens long.\")\n",
    "print(f\"Teenagers has {len(set(txt_clean))} unique tokens.\")\n",
    "\n",
    "print(f\"Teenagers' lexical diversity is {len(set(txt_clean))/len(txt_clean):.3f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3dc2f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdata\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
